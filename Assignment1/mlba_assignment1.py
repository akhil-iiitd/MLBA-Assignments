# -*- coding: utf-8 -*-
"""MLBA_Assignment1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1LhbZzAxxe8qXWbwan7cHuHCVlfHKLKc4

#**MLBA ASSIGNMENT - 1**
**Group - 70**

****
We have used RandomForest Classifier to train the model. For tokenisation, we have used Term Frequency-Inverse Document Frequency and implemented a custon encoding format. Then we applied smote method to account for the class imbalances present in the dataset

Library imports
"""

#Importing all the required libraries
import subprocess
packages_to_install = ['pandas', 'numpy','sklearn','imbalanced-learn']
for package in packages_to_install:
  subprocess.check_call(['pip', 'install', package])

import argparse
import pandas as pd
from sklearn.preprocessing import LabelEncoder
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score
from imblearn.over_sampling import SMOTE
import collections
import csv
from sklearn.svm import SVC

#Parsing the data from command line
parser=argparse.ArgumentParser()
parser.add_argument("--files",nargs='+',help="Train and test files")
args = parser.parse_args()
args=args.files
train_csv=args[0]
test_csv=args[1]
#Declaring custom encoder
label_encoder = LabelEncoder()
amino_acid_mapping = {char: i  for i, char in enumerate('ACDEFGHIKLMNPQRSTVWY')}

#Loading training data
train_data=pd.read_csv(train_csv)

#Applying TF_IDF to the given dataset
tfidf_list=[]

#Looping through all the training data sequence
for data in train_data["Sequence"]:
  code_length=len(data)
  code_count = collections.Counter(data)
  #Now making a dictionary for each letter in the sequence and their corresponsing count
  tf_idf_scores = {letter: count  for letter, count in code_count.items()}
  tfidf_list.append(tf_idf_scores)

#After finding the document frequency using TD_IDF, we will be finalising the encoded sequence in the list final_list

final_list=[]
for idf in tfidf_list:
  #Created a list with 21 0s
  temp_list=[0]*21
  for i in idf:
    #For each of the indices where the corresponsing label is present, we add the count to that index
    temp_list[amino_acid_mapping[i]]=idf[i]
  final_list.append(temp_list)

#converting sequences and labels as numpy arrays
Sequences=np.array(final_list)
Labels=np.array(train_data["Label"])

#Applying SMOTE to the given dataset
smote=SMOTE(random_state=42)
X_sample,y_resample=smote.fit_resample(Sequences,Labels)

#Splitting the data into training and testing samples
X_train, X_test, y_train, y_test = train_test_split(X_sample, y_resample, test_size=0.3, random_state=42)

#declaring the classifier, ie RF classifier with the various hyperparameters
rf_classifier = RandomForestClassifier(n_estimators=60, max_depth=None, min_samples_split=2)

#Fitting the training data with the testing data
rf_classifier.fit(X_train, y_train)

#Predicting the output values for the testing sequences
y_pred = rf_classifier.predict(X_test)

# Calculating the accuracy of out model
accuracy = accuracy_score(y_test, y_pred)
print(f"Test Accuracy of the model : {accuracy*100}")

#Reading the unlabelled original test dataset that has been given to classify
test_data=pd.read_csv(test_csv)

#Applying the TF_IDF on the test data as well
test_tfidf_list=[]
for data in test_data["Sequence"]:
  code_length=len(data)
  code_count = collections.Counter(data)
  tf_idf_scores = {letter: count  for letter, count in code_count.items()}
  test_tfidf_list.append(tf_idf_scores)

#COnverting them into the actual test sequence
test_final_list=[]
for idf in test_tfidf_list:
  #Created a list with 21 0s
  temp_list=[0]*21
  for i in idf:
    #For each of the indices where the corresponsing label is present, we add the count to that index
    temp_list[amino_acid_mapping[i]]=idf[i]
  test_final_list.append(temp_list)

#Predicting the labels for the test data
final_pred=rf_classifier.predict(test_final_list)

#Saving the data with ID and the corresponding label in a file output_rf_smote.csv
with open('./output/output_rf_smote_final.csv', mode='w', newline='') as file:
  writer = csv.writer(file)
  writer.writerow(['ID', 'Label'])
  for i in range(0,len(test_data["ID"])):
    writer.writerow([test_data["ID"][i],final_pred[i]])